{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6531447,"sourceType":"datasetVersion","datasetId":2937277},{"sourceId":8722154,"sourceType":"datasetVersion","datasetId":5234000},{"sourceId":8723614,"sourceType":"datasetVersion","datasetId":5235091},{"sourceId":8723628,"sourceType":"datasetVersion","datasetId":5235104}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycryptodome","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:41:25.925368Z","iopub.execute_input":"2024-06-18T19:41:25.925774Z","iopub.status.idle":"2024-06-18T19:41:38.260912Z","shell.execute_reply.started":"2024-06-18T19:41:25.925747Z","shell.execute_reply":"2024-06-18T19:41:38.259396Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (3.20.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = \"/kaggle/input/embedder/embedding_only_model.h5\"","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:41:22.147639Z","iopub.execute_input":"2024-06-18T19:41:22.148029Z","iopub.status.idle":"2024-06-18T19:41:22.152853Z","shell.execute_reply.started":"2024-06-18T19:41:22.148000Z","shell.execute_reply":"2024-06-18T19:41:22.151669Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics.pairwise import euclidean_distances as L2\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.applications import MobileNetV2\nimport tensorflow as tf\nimport os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm  # Import tqdm for the progress bar\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:41:11.458606Z","iopub.execute_input":"2024-06-18T19:41:11.459055Z","iopub.status.idle":"2024-06-18T19:41:15.875554Z","shell.execute_reply.started":"2024-06-18T19:41:11.459021Z","shell.execute_reply":"2024-06-18T19:41:15.874372Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"2024-06-18 19:41:12.274409: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-18 19:41:12.274486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-18 19:41:12.276372: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"embedder = load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:41:38.263312Z","iopub.execute_input":"2024-06-18T19:41:38.263738Z","iopub.status.idle":"2024-06-18T19:41:39.828799Z","shell.execute_reply.started":"2024-06-18T19:41:38.263702Z","shell.execute_reply":"2024-06-18T19:41:39.827453Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import sqlite3\nimport numpy as np\nfrom PIL import Image\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Random import get_random_bytes\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport os\nimport math \nimport cv2\nimport re\nfrom tqdm import tqdm\n\nsns.set_style('dark')\n\n# Create a connection to the SQLite database\nconn = sqlite3.connect('facial_recognition.db')\ncursor = conn.cursor()\n\n# Create a table for storing user embeddings\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS users (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    username TEXT NOT NULL,\n    embedding BLOB NOT NULL\n)\n''')\nconn.commit()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:48:31.159961Z","iopub.execute_input":"2024-06-18T19:48:31.160361Z","iopub.status.idle":"2024-06-18T19:48:31.379435Z","shell.execute_reply.started":"2024-06-18T19:48:31.160315Z","shell.execute_reply":"2024-06-18T19:48:31.378413Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Function to encrypt data\ndef encrypt_data(data, key):\n    iv = get_random_bytes(AES.block_size)  # Generate a new IV for each encryption\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    ct_bytes = cipher.encrypt(pad(data, AES.block_size))\n    return iv + ct_bytes  # Return IV + cipher text\n\n# Function to decrypt data\ndef decrypt_data(encrypted_data, key):\n    iv = encrypted_data[:AES.block_size]  # Extract the IV from the start of the data\n    ct = encrypted_data[AES.block_size:]  # Extract the cipher text\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    try:\n        pt = unpad(cipher.decrypt(ct), AES.block_size)\n        return pt\n    except ValueError as e:\n        print(\"Decryption error:\", e)\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:41:50.477719Z","iopub.execute_input":"2024-06-18T19:41:50.478131Z","iopub.status.idle":"2024-06-18T19:41:50.487900Z","shell.execute_reply.started":"2024-06-18T19:41:50.478100Z","shell.execute_reply":"2024-06-18T19:41:50.486426Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def load_and_preprocess_image(image_path):\n    with Image.open(image_path) as img:\n        img = img.resize((224, 224))\n        img = np.array(img.convert('RGB'), dtype=np.float32)\n        img = (img - 127.5) / 128.0  # Normalize to [-1, 1]\n    return img\n\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Function to process an image and get its embedding\ndef get_embedding(image_path, embedding_model):\n    # Load the image file, resize it, and convert to array\n    img = load_img(image_path, target_size=(224, 224))\n    img_array = img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array /= 255.0  # Normalize to [0, 1]\n\n    # Generate embedding\n    embedding = embedding_model.predict(img_array)\n    return embedding\n\n\n\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:41:55.357531Z","iopub.execute_input":"2024-06-18T19:41:55.357943Z","iopub.status.idle":"2024-06-18T19:41:55.368325Z","shell.execute_reply.started":"2024-06-18T19:41:55.357912Z","shell.execute_reply":"2024-06-18T19:41:55.367200Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def euclidean(x1,y1,x2,y2):\n    return ((x1-x2)**2 + (y1-y2)**2)**0.5\n\ndef align(x1,y1,x2,y2,img):\n    x3,y3 = 0,0\n    adj,hyp = 0,euclidean(x1,y1,x2,y2)\n    angle = 0\n    \n    if y1 > y2:\n        x3,y3 = x1,y2\n        adj = euclidean(x3,y3,x2,y2)\n        angle = -math.degrees(math.acos(adj/hyp))\n    else:\n        x3,y3 = x2,y1\n        adj = euclidean(x3,y3,x1,y1)\n        angle = math.degrees(math.acos(adj/hyp))\n        \n    M = cv2.getRotationMatrix2D((img.shape[1]//2,img.shape[0]//2), angle, 1)\n    out = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n    return out\n\ndef read_image(directory,image_path):\n    img = load_img(os.path.join(directory,image_path))\n    img = img_to_array(img)\n    faces = detector.detect_faces(img)\n    x1,y1 = faces[0]['keypoints']['left_eye']\n    x2,y2 = faces[0]['keypoints']['right_eye']\n    img = align(x1,y1,x2,y2,img)\n    faces = detector.detect_faces(img)\n    x,y,w,h = faces[0]['box']\n    img = img[y:y+h,x:x+w,:]\n    img /= 255.\n    img = cv2.resize(img,(224,224))\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:52:10.844881Z","iopub.execute_input":"2024-06-18T19:52:10.845326Z","iopub.status.idle":"2024-06-18T19:52:10.858468Z","shell.execute_reply.started":"2024-06-18T19:52:10.845283Z","shell.execute_reply":"2024-06-18T19:52:10.857086Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from mtcnn import MTCNN\nimport math","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:52:14.653741Z","iopub.execute_input":"2024-06-18T19:52:14.654131Z","iopub.status.idle":"2024-06-18T19:52:14.659217Z","shell.execute_reply.started":"2024-06-18T19:52:14.654104Z","shell.execute_reply":"2024-06-18T19:52:14.657874Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"detector = MTCNN()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:52:15.023409Z","iopub.execute_input":"2024-06-18T19:52:15.023848Z","iopub.status.idle":"2024-06-18T19:52:15.295707Z","shell.execute_reply.started":"2024-06-18T19:52:15.023815Z","shell.execute_reply":"2024-06-18T19:52:15.294378Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"directory = '/kaggle/input/testing'\nAbigail_img1 = read_image(directory,'Abigail 1.jpg')\nAbigail_img2 = read_image(directory,'Abigail 2.jpg')\nKizito_img1 = read_image(directory,'Kizito 1.jpg')\nKizito_img2 = read_image(directory, 'Kizito 2.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:03:04.902551Z","iopub.execute_input":"2024-06-18T20:03:04.902953Z","iopub.status.idle":"2024-06-18T20:03:14.264363Z","shell.execute_reply.started":"2024-06-18T20:03:04.902925Z","shell.execute_reply":"2024-06-18T20:03:14.263038Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_kizito1 = embedder.predict(np.expand_dims(Kizito_img1,axis=0))\nemb_kizito2 = embedder.predict(np.expand_dims(Kizito_img2,axis=0))\nemb_abigail1 = embedder.predict(np.expand_dims(Abigail_img1,axis=0))\nemb_abigail2 = embedder.predict(np.expand_dims(Abigail_img2,axis=0))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:03:19.336545Z","iopub.execute_input":"2024-06-18T20:03:19.337321Z","iopub.status.idle":"2024-06-18T20:03:19.766531Z","shell.execute_reply.started":"2024-06-18T20:03:19.337286Z","shell.execute_reply":"2024-06-18T20:03:19.765249Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"Abigail_img1 = img_to_array(Abigail_img1)\nAbigail_img2 = img_to_array(Abigail_img2)\nKizito_img1 = img_to_array(Kizito_img1)\nKizito_img2 = img_to_array(Kizito_img2)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:03:35.582695Z","iopub.execute_input":"2024-06-18T20:03:35.583112Z","iopub.status.idle":"2024-06-18T20:03:35.588918Z","shell.execute_reply.started":"2024-06-18T20:03:35.583080Z","shell.execute_reply":"2024-06-18T20:03:35.587776Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"emb_kizito1 = embedder.predict(np.array(Kizito_img1))\nemb_kizito2 = embedder.predict(Kizito_img2)\nemb_abigail1 = embedder.predict(Abigail_img1)\nemb_abigail2 = embedder.predict(Abigail_img2)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:04:47.875681Z","iopub.execute_input":"2024-06-18T20:04:47.876141Z","iopub.status.idle":"2024-06-18T20:04:48.027153Z","shell.execute_reply.started":"2024-06-18T20:04:47.876104Z","shell.execute_reply":"2024-06-18T20:04:48.025435Z"},"trusted":true},"execution_count":74,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m emb_kizito1 \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKizito_img1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m emb_kizito2 \u001b[38;5;241m=\u001b[39m embedder\u001b[38;5;241m.\u001b[39mpredict(Kizito_img2)\n\u001b[1;32m      3\u001b[0m emb_abigail1 \u001b[38;5;241m=\u001b[39m embedder\u001b[38;5;241m.\u001b[39mpredict(Abigail_img1)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","\u001b[0;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."],"ename":"ValueError","evalue":"as_list() is not defined on an unknown TensorShape.","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import euclidean_distances as L2, cosine_similarity as cs","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:54:51.480192Z","iopub.execute_input":"2024-06-18T19:54:51.480660Z","iopub.status.idle":"2024-06-18T19:54:51.486516Z","shell.execute_reply.started":"2024-06-18T19:54:51.480625Z","shell.execute_reply":"2024-06-18T19:54:51.484823Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom mtcnn.mtcnn import MTCNN\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics.pairwise import euclidean_distances as L2\nimport math\n\n# Initialize the face detector\ndetector = MTCNN()\n\n# Function to compute Euclidean distance\ndef euclidean(x1, y1, x2, y2):\n    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n\n# Function to align the face\ndef align(x1, y1, x2, y2, img):\n    x3, y3 = 0, 0\n    adj, hyp = 0, euclidean(x1, y1, x2, y2)\n    angle = 0\n    \n    if y1 > y2:\n        x3, y3 = x1, y2\n        adj = euclidean(x3, y3, x2, y2)\n        angle = -math.degrees(math.acos(adj / hyp))\n    else:\n        x3, y3 = x2, y1\n        adj = euclidean(x3, y3, x1, y1)\n        angle = math.degrees(math.acos(adj / hyp))\n        \n    M = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), angle, 1)\n    out = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n    return out\n\n# Function to read and preprocess image\ndef read_image(directory, image_path):\n    img = load_img(os.path.join(directory, image_path))\n    img = img_to_array(img)\n    faces = detector.detect_faces(img)\n    x1, y1 = faces[0]['keypoints']['left_eye']\n    x2, y2 = faces[0]['keypoints']['right_eye']\n    img = align(x1, y1, x2, y2, img)\n    faces = detector.detect_faces(img)\n    x, y, w, h = faces[0]['box']\n    img = img[y:y + h, x:x + w, :]\n    img /= 255.0\n    img = cv2.resize(img, (224, 224))\n    return img\n\n# Load the embedding model\nmodel_path = \"/kaggle/input/embedder/embedding_only_model.h5\"\nembedder = load_model(model_path, compile=False)\n\n# Directory containing the images\ndirectory = '/kaggle/input/testing'\n\n# Read and preprocess images\nAbigail_img1 = read_image(directory, 'Abigail 1.jpg')\nAbigail_img2 = read_image(directory, 'Abigail 2.jpg')\nKizito_img1 = read_image(directory, 'Kizito 1.jpg')\nKizito_img2 = read_image(directory, 'Kizito 2.jpg')\n\n# Compute embeddings\nemb_kizito1 = embedder.predict(np.expand_dims(Kizito_img1, axis=0))\nemb_kizito2 = embedder.predict(np.expand_dims(Kizito_img2, axis=0))\nemb_abigail1 = embedder.predict(np.expand_dims(Abigail_img1, axis=0))\nemb_abigail2 = embedder.predict(np.expand_dims(Abigail_img2, axis=0))\n\n# Compute Euclidean distance\ndistance_kizito = L2(emb_kizito1.reshape(1, -1), emb_kizito2.reshape(1, -1))\ndistance_abigail = L2(emb_abigail1.reshape(1, -1), emb_abigail2.reshape(1, -1))\n\nprint(\"Distance between Kizito images:\", distance_kizito)\nprint(\"Distance between Abigail images:\", distance_abigail)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:11:49.917108Z","iopub.execute_input":"2024-06-18T20:11:49.918294Z","iopub.status.idle":"2024-06-18T20:12:02.913915Z","shell.execute_reply.started":"2024-06-18T20:11:49.918250Z","shell.execute_reply":"2024-06-18T20:12:02.912760Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\nDistance between Kizito images: [[0.06500901]]\nDistance between Abigail images: [[0.14541507]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# distance_kizito = L2(emb_kizito1.reshape(1, -1), emb_abigail1.reshape(1, -1))\ndistance_abigail = L2(emb_abigail1.reshape(1, -1), emb_abigail2.reshape(1, -1))\n\n\n\n# print(\"Distance between Kizito images:\", distance_kizito)\nprint(\"Distance between Abigail images:\", distance_abigail)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:17:21.835493Z","iopub.execute_input":"2024-06-18T20:17:21.836022Z","iopub.status.idle":"2024-06-18T20:17:21.843932Z","shell.execute_reply.started":"2024-06-18T20:17:21.835983Z","shell.execute_reply":"2024-06-18T20:17:21.842795Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Distance between Abigail images: [[0.14541507]]\n","output_type":"stream"}]},{"cell_type":"code","source":"L2(Kizito_img1, Kizito_img2)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:54:55.096526Z","iopub.execute_input":"2024-06-18T19:54:55.096947Z","iopub.status.idle":"2024-06-18T19:54:55.192845Z","shell.execute_reply.started":"2024-06-18T19:54:55.096917Z","shell.execute_reply":"2024-06-18T19:54:55.191289Z"},"trusted":true},"execution_count":59,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mL2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKizito_img1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKizito_img2\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:300\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_distances\u001b[39m(\n\u001b[1;32m    225\u001b[0m     X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, Y_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, X_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    226\u001b[0m ):\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m           [1.41421356]])\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X_norm_squared \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m         X_norm_squared \u001b[38;5;241m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:155\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    147\u001b[0m         X,\n\u001b[1;32m    148\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    164\u001b[0m         Y,\n\u001b[1;32m    165\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m     )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    921\u001b[0m     _assert_all_finite(\n\u001b[1;32m    922\u001b[0m         array,\n\u001b[1;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."],"ename":"ValueError","evalue":"Found array with dim 3. check_pairwise_arrays expected <= 2.","output_type":"error"}]},{"cell_type":"code","source":"def register_user(username, image_path, key,embedder):\n    embedding = get_embedding(image_path, embedder)\n    embedding_bytes = embedding.tobytes()\n    encrypted_embedding = encrypt_data(embedding_bytes, key)\n\n    # Store username and encrypted embedding in the database\n    cursor.execute('INSERT INTO users (username, embedding) VALUES (?, ?)', (username, encrypted_embedding))\n    conn.commit()\n    print(f\"User {username} registered successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:15:46.892125Z","iopub.execute_input":"2024-06-18T15:15:46.892523Z","iopub.status.idle":"2024-06-18T15:15:46.897985Z","shell.execute_reply.started":"2024-06-18T15:15:46.892494Z","shell.execute_reply":"2024-06-18T15:15:46.896845Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Example usage\nkey = get_random_bytes(16)  # AES key\nregister_user('Caleb', '/kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/110393.jpg', key, embedder)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:18:24.990194Z","iopub.execute_input":"2024-06-18T15:18:24.990509Z","iopub.status.idle":"2024-06-18T15:18:25.099992Z","shell.execute_reply.started":"2024-06-18T15:18:24.990487Z","shell.execute_reply":"2024-06-18T15:18:25.098883Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\nUser Caleb registered successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"def authenticate_user(username, image_path, key, embedder, threshold=1.3):\n    current_embedding = get_embedding(image_path, embedder)\n\n    # Retrieve the stored embedding from the database\n    cursor.execute('SELECT embedding FROM users WHERE username = ?', (username,))\n    result = cursor.fetchone()\n\n    if result:\n        stored_encrypted_embedding = result[0]\n        stored_embedding_bytes = decrypt_data(stored_encrypted_embedding, key)\n        if stored_embedding_bytes:\n            stored_embedding = np.frombuffer(stored_embedding_bytes, dtype=current_embedding.dtype)\n            dist = L2(current_embedding.reshape(1, -1), stored_embedding.reshape(1, -1))[0][0]\n            print(\"Distance:\", dist)\n            if dist <= threshold:\n                print(f\"User {username} authenticated successfully.\")\n            else:\n                print(f\"Authentication failed for user {username}.\")\n        else:\n            print(\"Decryption error occurred.\")\n    else:\n        print(f\"User {username} not found.\")\n\n# Example usage\nauthenticate_user('Caleb', '/kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/105432.jpg', key, embedder)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:19:23.172445Z","iopub.execute_input":"2024-06-18T15:19:23.172813Z","iopub.status.idle":"2024-06-18T15:19:23.412043Z","shell.execute_reply.started":"2024-06-18T15:19:23.172785Z","shell.execute_reply":"2024-06-18T15:19:23.411001Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\nDistance: 0.093240954\nUser Caleb authenticated successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"authenticate_user('Daniel', '/kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/107918.jpg', key, embedder)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:06:50.109491Z","iopub.execute_input":"2024-06-18T15:06:50.109904Z","iopub.status.idle":"2024-06-18T15:06:50.234826Z","shell.execute_reply.started":"2024-06-18T15:06:50.109872Z","shell.execute_reply":"2024-06-18T15:06:50.233771Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\nDecryption error: Padding is incorrect.\nDecryption error occurred.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Path to your dataset CSV and images directory\ncsv_path = '/kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/triplets.csv'\nimage_dir = '/kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images'\n\n# Load the triplets CSV\ntriplets_df = pd.read_csv(csv_path)\ntriplets_df2 = triplets_df.iloc[:40]  # Select first 40 rows\n\n# Extract 7 file paths of anchors, positives, and negatives\ndef get_file_paths(df, image_dir, num_samples=7):\n    file_paths = []\n    for index, row in df.iterrows():\n        if index >= num_samples:\n            break\n        anchor_path = os.path.join(image_dir, row['anchor'])\n        positive_path = os.path.join(image_dir, row['pos'])\n        negative_path = os.path.join(image_dir, row['neg'])\n        file_paths.append((anchor_path, positive_path, negative_path))\n    return file_paths\n\nfile_paths = get_file_paths(triplets_df2, image_dir, num_samples=7)\n\n# Print the file paths\nfor i, paths in enumerate(file_paths):\n    anchor, positive, negative = paths\n    print(f\"Sample {i + 1}:\")\n    print(f\"  Anchor: {anchor}\")\n    print(f\"  Positive: {positive}\")\n    print(f\"  Negative: {negative}\")\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:07:39.005525Z","iopub.execute_input":"2024-06-18T00:07:39.006105Z","iopub.status.idle":"2024-06-18T00:07:39.094962Z","shell.execute_reply.started":"2024-06-18T00:07:39.006065Z","shell.execute_reply":"2024-06-18T00:07:39.093714Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Sample 1:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/056279.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/108998.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/030848.jpg\n\nSample 2:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/024091.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/000023.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/093653.jpg\n\nSample 3:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/122082.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/045833.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/188283.jpg\n\nSample 4:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/110393.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/021233.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/178433.jpg\n\nSample 5:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/101388.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/056784.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/105432.jpg\n\nSample 6:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/143743.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/107918.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/079773.jpg\n\nSample 7:\n  Anchor: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/093187.jpg\n  Positive: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/101049.jpg\n  Negative: /kaggle/input/celeba-face-recognition-triplets/CelebA FR Triplets/CelebA FR Triplets/images/141930.jpg\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!pip install streamlit mtcnn opencv-python-headless pycryptodome\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:11:22.997798Z","iopub.execute_input":"2024-06-18T19:11:22.998366Z","iopub.status.idle":"2024-06-18T19:11:39.304948Z","shell.execute_reply.started":"2024-06-18T19:11:22.998309Z","shell.execute_reply":"2024-06-18T19:11:39.303445Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.35.0-py2.py3-none-any.whl.metadata (8.5 kB)\nCollecting mtcnn\n  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.10.0.82)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (3.20.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<2,>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=16.8 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.0)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.9.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.41)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\nCollecting watchdog>=2.1.5 (from streamlit)\n  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\nRequirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from mtcnn) (3.3.3)\nRequirement already satisfied: opencv-python>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from mtcnn) (4.10.0.82)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras>=2.0.0->mtcnn) (1.4.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=2.0.0->mtcnn) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras>=2.0.0->mtcnn) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=2.0.0->mtcnn) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras>=2.0.0->mtcnn) (0.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=16.8->streamlit) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.16.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\nDownloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: watchdog, pydeck, mtcnn, streamlit\nSuccessfully installed mtcnn-0.1.1 pydeck-0.9.1 streamlit-1.35.0 watchdog-4.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyngrok\nfrom pyngrok import ngrok\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:11:43.686661Z","iopub.execute_input":"2024-06-18T19:11:43.687093Z","iopub.status.idle":"2024-06-18T19:11:56.160747Z","shell.execute_reply.started":"2024-06-18T19:11:43.687058Z","shell.execute_reply":"2024-06-18T19:11:56.159596Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting pyngrok\n  Downloading pyngrok-7.1.6-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.1)\nDownloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.1.6\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport cv2\nimport numpy as np\nfrom mtcnn.mtcnn import MTCNN\nfrom tensorflow.keras.models import load_model\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Random import get_random_bytes\nimport sqlite3\n\n# Function to encrypt data\ndef encrypt_data(data, key):\n    iv = get_random_bytes(AES.block_size)  # Generate a new IV for each encryption\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    ct_bytes = cipher.encrypt(pad(data, AES.block_size))\n    return iv + ct_bytes  # Return IV + cipher text\n\n# Function to decrypt data\ndef decrypt_data(encrypted_data, key):\n    iv = encrypted_data[:AES.block_size]  # Extract the IV from the start of the data\n    ct = encrypted_data[AES.block_size:]  # Extract the cipher text\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    try:\n        pt = unpad(cipher.decrypt(ct), AES.block_size)\n        return pt\n    except ValueError as e:\n        print(\"Decryption error:\", e)\n        return None\n\n# Function to load and preprocess image\ndef load_and_preprocess_image(image):\n    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (224, 224))\n    img = np.array(img, dtype=np.float32)\n    img = (img - 127.5) / 128.0  # Normalize to [-1, 1]\n    return np.expand_dims(img, axis=0)\n\n# Function to get embedding\ndef get_embedding(image, model):\n    preprocessed_image = load_and_preprocess_image(image)\n    embedding = model.predict(preprocessed_image)\n    return embedding\n\n# Function to capture image using webcam\ndef capture_image():\n    cap = cv2.VideoCapture(0)\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            continue\n        cv2.imshow('Press \"s\" to capture and \"q\" to quit', frame)\n        key = cv2.waitKey(1) & 0xFF\n        if key == ord('s'):\n            captured_image = frame\n            break\n        elif key == ord('q'):\n            captured_image = None\n            break\n    cap.release()\n    cv2.destroyAllWindows()\n    return captured_image\n\n# Function to detect face using MTCNN\ndef detect_face(image):\n    detector = MTCNN()\n    result = detector.detect_faces(image)\n    if result:\n        bounding_box = result[0]['box']\n        x, y, w, h = bounding_box\n        face = image[y:y+h, x:x+w]\n        return face\n    return None\n\n# Database setup\nconn = sqlite3.connect('facial_recognition.db')\ncursor = conn.cursor()\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS users (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    username TEXT NOT NULL,\n    embedding BLOB NOT NULL\n)\n''')\nconn.commit()\n\n# Load the embedding model\nmodel_path = \"/kaggle/input/embedder/embedding_only_model.h5\"\nembedding_model = load_model(model_path, compile=False)\n\n# Streamlit app\nst.title(\"Facial Recognition System\")\n\nkey = get_random_bytes(16)  # AES key\n\n# Login/Register\nchoice = st.sidebar.selectbox(\"Login/Register\", [\"Login\", \"Register\"])\n\nif choice == \"Register\":\n    st.header(\"Register\")\n    username = st.text_input(\"Enter Username\")\n    if st.button(\"Capture and Register\"):\n        image = capture_image()\n        if image is not None:\n            face = detect_face(image)\n            if face is not None:\n                embedding = get_embedding(face, embedding_model)\n                embedding_bytes = embedding.tobytes()\n                encrypted_embedding = encrypt_data(embedding_bytes, key)\n                cursor.execute('INSERT INTO users (username, embedding) VALUES (?, ?)', (username, encrypted_embedding))\n                conn.commit()\n                st.success(f\"User {username} registered successfully.\")\n            else:\n                st.error(\"No face detected. Please try again.\")\n        else:\n            st.error(\"Image capture failed. Please try again.\")\n\nelif choice == \"Login\":\n    st.header(\"Login\")\n    username = st.text_input(\"Enter Username\")\n    if st.button(\"Capture and Authenticate\"):\n        image = capture_image()\n        if image is not None:\n            face = detect_face(image)\n            if face is not None:\n                current_embedding = get_embedding(face, embedding_model)\n                cursor.execute('SELECT embedding FROM users WHERE username = ?', (username,))\n                result = cursor.fetchone()\n                if result:\n                    stored_encrypted_embedding = result[0]\n                    stored_embedding_bytes = decrypt_data(stored_encrypted_embedding, key)\n                    if stored_embedding_bytes:\n                        stored_embedding = np.frombuffer(stored_embedding_bytes, dtype=current_embedding.dtype)\n                        dist = L2(current_embedding.reshape(1, -1), stored_embedding.reshape(1, -1))[0][0]\n                        if dist <= 1.3:\n                            st.success(f\"User {username} authenticated successfully.\")\n                        else:\n                            st.error(f\"Authentication failed for user {username}.\")\n                    else:\n                        st.error(\"Decryption error occurred.\")\n                else:\n                    st.error(f\"User {username} not found.\")\n            else:\n                st.error(\"No face detected. Please try again.\")\n        else:\n            st.error(\"Image capture failed. Please try again.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:36:00.951238Z","iopub.execute_input":"2024-06-18T15:36:00.951571Z","iopub.status.idle":"2024-06-18T15:36:00.961084Z","shell.execute_reply.started":"2024-06-18T15:36:00.951542Z","shell.execute_reply":"2024-06-18T15:36:00.959843Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Overwriting app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport cv2\nimport numpy as np\nfrom mtcnn.mtcnn import MTCNN\nfrom tensorflow.keras.models import load_model\nimport sqlite3\nfrom sklearn.metrics.pairwise import euclidean_distances as L2\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Function to load and preprocess image\ndef load_and_preprocess_image(image):\n    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (224, 224))\n    img = np.array(img, dtype=np.float32)\n    img = (img - 127.5) / 128.0  # Normalize to [-1, 1]\n    return np.expand_dims(img, axis=0)\n\n# def load_and_preprocess_image(image):\n#         img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         img = cv2.resize(img, (224, 224))\n#         img = np.array(img, dtype=np.float32)\n#         img = (img - 127.5) / 128.0  # Normalize to [-1, 1]\n#         return img\n\n\ndef get_embedding(image, embedding_model):\n    preprocessed_image = load_and_preprocess_image(image)\n    # Generate embedding\n    embedding = embedding_model.predict(preprocessed_image)\n    return embedding\n\n# # Function to get embedding\n# def get_embedding(image, model):\n#     preprocessed_image = load_and_preprocess_image(image)\n#     embedding = model.predict(preprocessed_image)\n#     return embedding\n\n# Function to detect face using MTCNN\ndef detect_face(image):\n    detector = MTCNN()\n    result = detector.detect_faces(image)\n    if result:\n        bounding_box = result[0]['box']\n        x, y, w, h = bounding_box\n        face = image[y:y+h, x:x+w]\n        return face\n    return None\n\n# Database setup\nconn = sqlite3.connect('facial_recognition.db')\ncursor = conn.cursor()\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS users (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    username TEXT NOT NULL,\n    embedding BLOB NOT NULL\n)\n''')\nconn.commit()\n\n# Load the embedding model\nmodel_path = \"/kaggle/input/embedder/embedding_only_model.h5\"\nembedding_model = load_model(model_path, compile=False)\n\n# Streamlit app\nst.title(\"Facial Recognition System\")\n\n# Login/Register\nchoice = st.sidebar.selectbox(\"Register/Login\", [ \"Register\", \"Login\"])\n\nif choice == \"Register\":\n    st.header(\"Register\")\n    username = st.text_input(\"Enter Username\")\n    uploaded_file = st.file_uploader(\"Upload a face image\", type=[\"jpg\", \"jpeg\", \"png\"])\n    if st.button(\"Register\") and uploaded_file is not None:\n        image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), 1)\n        face = detect_face(image)\n        if face is not None:\n            embedding = get_embedding(face, embedding_model)\n            embedding_bytes = embedding.tobytes()\n            cursor.execute('INSERT INTO users (username, embedding) VALUES (?, ?)', (username, embedding_bytes))\n            conn.commit()\n            st.success(f\"User {username} registered successfully.\")\n        else:\n            st.error(\"No face detected. Please try again.\")\nelif choice == \"Login\":\n    st.header(\"Login\")\n    username = st.text_input(\"Enter Username\")\n    uploaded_file = st.file_uploader(\"Upload a face image\", type=[\"jpg\", \"jpeg\", \"png\"])\n    if st.button(\"Login\") and uploaded_file is not None:\n        image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), 1)\n        face = detect_face(image)\n        if face is not None:\n            current_embedding = get_embedding(face, embedding_model)\n            cursor.execute('SELECT embedding FROM users WHERE username = ?', (username,))\n            result = cursor.fetchone()\n            if result:\n                stored_embedding_bytes = result[0]\n                stored_embedding = np.frombuffer(stored_embedding_bytes, dtype=current_embedding.dtype)\n                \n                # Check for finite values in embeddings\n                if not np.all(np.isfinite(current_embedding)):\n                    st.error(\"Non-finite values in current embedding.\")\n                elif not np.all(np.isfinite(stored_embedding)):\n                    st.error(\"Non-finite values in stored embedding.\")\n                else:\n                    dist = L2(current_embedding.reshape(1, -1), stored_embedding.reshape(1, -1))[0][0]\n                    if dist <= 1.3:\n                        st.success(f\"User {username} authenticated successfully.\")\n                    else:\n                        st.error(f\"Authentication failed for user {username}.\")\n            else:\n                st.error(f\"User {username} not found.\")\n        else:\n            st.error(\"No face detected. Please try again.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:29:43.690108Z","iopub.execute_input":"2024-06-18T19:29:43.690568Z","iopub.status.idle":"2024-06-18T19:29:43.701208Z","shell.execute_reply.started":"2024-06-18T19:29:43.690529Z","shell.execute_reply":"2024-06-18T19:29:43.700016Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Overwriting app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!ngrok config add-authtoken 2VJXf1SjlcpG5WPLyrgDcEaM2ct_7KytqnABitp5VfqfxZCYf","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:25:05.480250Z","iopub.execute_input":"2024-06-18T19:25:05.481262Z","iopub.status.idle":"2024-06-18T19:25:06.693408Z","shell.execute_reply.started":"2024-06-18T19:25:05.481215Z","shell.execute_reply":"2024-06-18T19:25:06.692105Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","output_type":"stream"}]},{"cell_type":"code","source":"\n!wget -q -O - ipv4.icanhazip.com","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:25:06.695610Z","iopub.execute_input":"2024-06-18T19:25:06.695982Z","iopub.status.idle":"2024-06-18T19:25:07.740475Z","shell.execute_reply.started":"2024-06-18T19:25:06.695949Z","shell.execute_reply":"2024-06-18T19:25:07.738971Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"35.236.179.101\n","output_type":"stream"}]},{"cell_type":"code","source":"!npm install -g localtunnel\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:25:07.743098Z","iopub.execute_input":"2024-06-18T19:25:07.743605Z","iopub.status.idle":"2024-06-18T19:25:10.276927Z","shell.execute_reply.started":"2024-06-18T19:25:07.743559Z","shell.execute_reply":"2024-06-18T19:25:10.275492Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\u001b[K\u001b[?25hm##################\u001b[0m] - reify:yargs: \u001b[32;40mtiming\u001b[0m \u001b[35mreifyNode:node_modules/localtunnel/n\u001b[0m\u001b[Kmpleted in\u001b[0m\u001b[K\nchanged 22 packages in 1s\n\n3 packages are looking for funding\n  run `npm fund` for details\n","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run app.py & npx localtunnel --port 8501\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:29:48.948083Z","iopub.execute_input":"2024-06-18T19:29:48.949175Z","iopub.status.idle":"2024-06-18T19:36:20.902732Z","shell.execute_reply.started":"2024-06-18T19:29:48.949132Z","shell.execute_reply":"2024-06-18T19:36:20.901313Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\u001b[0m\n\u001b[0m\n\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n\u001b[0m\n\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.179.101:8501\u001b[0m\n\u001b[0m\nyour url is: https://slick-colts-slide.loca.lt\n2024-06-18 19:30:12.123817: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-18 19:30:12.123893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-18 19:30:12.125756: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n^C\n\u001b[34m  Stopping...\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}